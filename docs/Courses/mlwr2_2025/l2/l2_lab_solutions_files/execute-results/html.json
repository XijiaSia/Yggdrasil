{
  "hash": "9676e37c8cd0faaed23563a18e8cd928",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Solutions to Lab 1\"\neditor: source\n---\n\n\n\n\n\n\n\n# Task 1: Image reconstruction\n\nIn the next series of tasks, we implement image reconstruction with HWD dataset.\n\n**Task 1.1**: Choose your favorite number. \nUse the function 'image' to display the first 24 cases.\nBelow is an example of the usage method for the function `image()`.\nIn the following R chunk, the first two lines are about color settings. \nYou can also try your favorite color palette. \nIn the third line, `X` represents all images of your favorite number, which refers to the part of the `Dat` matrix in R space excluding the first column.\nThe last line generates the plot of the 8th image in `X`.\n\n```r\ncolors = c('white','black')\ncus_col <- colorRampPalette(colors=colors)\ntemp = matrix(X[8,256:1],16,16,byrow=T)[,16:1]\nimage(t(temp), col=cus_col(256), frame = T, axes = F)\n```\n\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n\nChoose all the images of my favorite number:\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nX = dat[which(dat[,1] == 4), -1]\ndim(X)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 652 256\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\nVisualize the first 24 images in the dataset by using \n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncolors = c('white','black')\ncus_col <- colorRampPalette(colors=colors)\n\npar(mfrow = c(4,6), mar = rep(1,4))\nfor(i in 1:24){\n  temp= matrix(X[i,256:1],16,16,byrow=T)[,16:1]\n  image(t(temp), col=cus_col(256), frame = T, axes = F)\n  title(paste(\"ID: \", i))\n}\n```\n\n::: {.cell-output-display}\n![](l2_lab_solutions_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n\n\n**Task 1.2**: Do PCA on your data set. Display the first 4 and the last 4 principal vectors (eigenvectors) as $16 \\times 16$ images. \n\n**Task 1.3**: Calculate all the PCs for all the images of your favorite number.\n\n**Task 1.4**: Image reconstruction. \nReconstruct an image in your data set by its first 30, 60, 100, 150, and 200 principal components separately. \nPut the original image and five approximated images in one plot. \nFor each approximated image, calculate and report the mean square errors.  \n\n<!---\n$|| \\textbf{x}- \\widehat{\\textbf{x}} ||^2/p$, where $\\textbf{x}_{p\\times 1}$ denotes the original image,  $\\widehat{\\textbf{x}}_{p \\times1}$ denotes the approximated image, and $p = 256$ is the number of pixels in a image.\n--->\n\n# Task 2: Train a classifier with extracted features\n\nBuild a classifier based on the first two principal components (PCs) to classify the images of digits 5 and 6. The following procedure is suggested to solve this task.\n\n  1. Create a new working dataset that contains all the images of 5 and 6.\n  2. Split the data set into training set ($80\\%$) and testing set ($20\\%$) by random sampling.\n  3. Do PCA on the training set. Use the eigenvectors of the sample covariance matrix of the training set to calculate the PCs for both the training set and testing set. \n  4. Use PCs of the training set to build the classifier\n  5. Apply your classifier to the testing set PCs and calculate the accuracy.\n\nCan you achieve this level of accuracy using only two variables from the original dataset to build the classifier? Think about it.\n\n<!--- End  --->\n<div style=\"text-align: center; margin: 30px 0\">\n[**Lecture 2 Homepage**](l2_home.qmd)\n</div>\n<!--- --->",
    "supporting": [
      "l2_lab_solutions_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}